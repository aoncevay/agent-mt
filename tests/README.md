# Workflow Testing Scripts

This directory contains test scripts to validate workflow implementations.

## Test Scripts

### 1. `test_workflow_prompts.py`
**Purpose**: Validates that prompts are correctly constructed with:
- Previous agent outputs included in subsequent prompts
- Terminology included when `use_terminology=True`
- Memory/state correctly passed between agents

**Usage**:
```bash
python tests/test_workflow_prompts.py
```

**What it tests**:
- Prompt construction (not LLM execution)
- Assertions that verify expected content is present
- No AWS/Bedrock calls required

**Output**: Pass/fail for each workflow's prompt chain

---

### 2. `test_workflow_execution.py`
**Purpose**: Runs actual workflow executions on a small test sample to verify:
- Workflows can execute end-to-end
- Outputs are produced correctly
- Result structure is valid

**Usage**:
```bash
# Test a single workflow
python tests/test_workflow_execution.py --workflow ADT_multi_agents --model qwen3-32b

# Test all workflows
python tests/test_workflow_execution.py --workflow all --model qwen3-32b

# Test with terminology
python tests/test_workflow_execution.py --workflow all --model qwen3-32b --use_terminology

# Skip certain workflows
python tests/test_workflow_execution.py --workflow all --model qwen3-32b --skip zero_shot zero_shot_term
```

**What it tests**:
- Actual LLM execution (requires AWS credentials)
- Output structure validation
- Token counting
- Latency measurement

**Output**: Execution results for each workflow

---

### 3. `test_prompt_extraction.py`
**Purpose**: Extracts and inspects actual prompts generated by workflows for manual inspection.

**Usage**:
```bash
# Extract prompts from all workflows
python tests/test_prompt_extraction.py --workflow all

# Extract from specific workflow
python tests/test_prompt_extraction.py --workflow ADT_multi_agents

# Save prompts to JSON file
python tests/test_prompt_extraction.py --workflow all --save-prompts
```

**What it does**:
- Generates prompts without executing workflows
- Analyzes prompts for expected content
- Optionally saves prompts to JSON for inspection

**Output**: Prompt analysis and optional JSON file

---

## Running Tests on AWS Server

### Quick Test (Prompt Validation Only)
```bash
# No AWS calls needed
python tests/test_workflow_prompts.py
```

### Full Test (Execution + Prompts)
```bash
# Run prompt validation (no AWS needed)
python tests/test_workflow_prompts.py

# Run execution tests (smaller model for speed)
# Note: Requires config.env with AWS credentials
python tests/test_workflow_execution.py --workflow all --model qwen3-32b

# Extract and save prompts for inspection
python tests/test_prompt_extraction.py --workflow all --save-prompts
```

### Testing Specific Workflows
```bash
# Test new ADT workflow
python tests/test_workflow_execution.py --workflow ADT_multi_agents --model qwen3-32b --use_terminology

# Test with terminology
python tests/test_workflow_execution.py --workflow MAATS_multi_agents --model qwen3-32b --use_terminology
```

---

## What to Look For

### ✅ Success Indicators
1. **Prompt Validation**: All assertions pass
2. **Execution**: Workflows complete without errors
3. **Output Structure**: Results contain expected keys (`outputs`, `tokens_input`, `tokens_output`, `latency`)
4. **Output Content**: Each output is a non-empty string
5. **Terminology**: When `--use_terminology` is set, prompts contain terminology dictionary

### ⚠️ Warning Signs
1. **Missing Content**: Prompts don't contain expected previous outputs
2. **Terminology Not Included**: Terminology flag set but not in prompts
3. **Empty Outputs**: Workflow completes but outputs are empty
4. **Token Count Issues**: Token counts are 0 (may indicate metadata issues)

---

## Test Data

All tests use the same sample text:
```
The United Nations (UN) is an international organization. 
It was founded in 1945. 
The UN promotes peace and security worldwide.
```

With terminology:
- "United Nations" → ["联合国", "UN"]
- "international organization" → ["国际组织"]
- "peace and security" → ["和平与安全"]

---

## Troubleshooting

### Import Errors
Make sure you're running from the project root:
```bash
cd /path/to/agent-mt
python tests/test_workflow_prompts.py
```

### AWS Credentials
For execution tests, ensure `config.env` file exists with AWS credentials:
```bash
# Check that config.env exists
cat config.env
```

### Model Not Available
If a model isn't available, skip it:
```bash
python tests/test_workflow_execution.py --workflow all --model qwen3-32b --skip qwen3-235b
```

